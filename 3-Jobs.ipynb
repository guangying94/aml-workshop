{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Azure ML SDK for jobs\n",
        "Sample to leverage Azure ML SDK to define job and execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1741229406025
        }
      },
      "outputs": [],
      "source": [
        "subscription_id = \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n",
        "resource_group = \"RESOURCE_GROUP_NAME\"\n",
        "workspace = \"WORKSPACE_NAME\"\n",
        "region = \"REGION\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1741229411523
        }
      },
      "outputs": [],
      "source": [
        "# Define the workspace client\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# authenticate\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "SUBSCRIPTION=subscription_id\n",
        "RESOURCE_GROUP=resource_group\n",
        "WS_NAME=workspace\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=SUBSCRIPTION,\n",
        "    resource_group_name=RESOURCE_GROUP,\n",
        "    workspace_name=WS_NAME,\n",
        ")\n",
        "\n",
        "# Verify that the handle works correctly.\n",
        "ws = ml_client.workspaces.get(WS_NAME)\n",
        "print(ws.location,\":\", ws.resource_group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## AML Compute Target\n",
        "AML jobs execute at compute cluster level, which is scale accordingly, and the compute cluster is sharable with other users. There's a queue system at the backend to execute the jobs being submitted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1741229699564
        }
      },
      "outputs": [],
      "source": [
        "# Try to retrieve AML compute, and create AML compute if the compute cluster is not available\n",
        "\n",
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# specify aml compute name.\n",
        "cpu_compute_target = \"ws-aml-cpu-01\"\n",
        "\n",
        "try:\n",
        "    ml_client.compute.get(cpu_compute_target)\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "    compute = AmlCompute(\n",
        "        name=cpu_compute_target, size=\"STANDARD_D2_V2\", min_instances=0, max_instances=2\n",
        "    )\n",
        "    ml_client.compute.begin_create_or_update(compute).result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## AML Environment\n",
        "To execute the job, the code will be executed in AML Environment, which is a container image executed in.\n",
        "\n",
        "More information here: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-environments-v2?view=azureml-api-2&tabs=cli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1741241304711
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Environment, BuildContext\n",
        "\n",
        "env_docker_conda = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/curated/sklearn-1.5:21\",\n",
        "    conda_file=\"./conda-yamls/pydata.yaml\",\n",
        "    name=\"workshop-conda-env\",\n",
        "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env_docker_conda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1741241491854
        }
      },
      "outputs": [],
      "source": [
        "# Define MLFlow tracking URI\n",
        "mlflow_tracking_uri = f\"azureml://{region}.api.azureml.ms/mlflow/v1.0/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}\"\n",
        "\n",
        "print(f\"Update script with MLFlow Tracking URI: {mlflow_tracking_uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## AML Submit Jobs\n",
        "Submit a job to AML Compute and the custom environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1741242192342
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command, Input\n",
        "import mltable\n",
        "\n",
        "# Get the env definition\n",
        "conda_env = ml_client.environments.get(name=\"workshop-conda-env\", version=\"1\")\n",
        "\n",
        "# Get the mltable definition\n",
        "titanic_version = 'xxxx'\n",
        "data_asset = ml_client.data.get(name=\"titanic-cloud-example\", version=titanic_version)\n",
        "\n",
        "# define the command\n",
        "command_job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python main.py --input ${{inputs.mltable}} --mlflow_uri ${{inputs.mlflow_uri}}\",\n",
        "    environment=conda_env,\n",
        "    inputs={\n",
        "        \"mltable\": Input(type=\"mltable\", path=data_asset.id),\n",
        "        \"mlflow_uri\": mlflow_tracking_uri\n",
        "    },\n",
        "\n",
        "    ## cpu compute target created above\n",
        "    compute=cpu_compute_target,\n",
        ")\n",
        "\n",
        "# submit the command\n",
        "returned_job = ml_client.jobs.create_or_update(command_job)\n",
        "\n",
        "# get a URL for the status of the job\n",
        "returned_job.studio_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## AML Register Model\n",
        "Once the model is trained, register the model for others to consume.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1741242557976
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "run_model = Model(\n",
        "    path=\"azureml://jobs/{}/outputs/artifacts/paths/model/\".format(returned_job.name),\n",
        "    name=\"workshop-titanic-regression\",\n",
        "    description=\"Model created for workshop\",\n",
        "    type=AssetTypes.MLFLOW_MODEL\n",
        ")\n",
        "\n",
        "ml_client.models.create_or_update(run_model)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
